{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5e1cb8",
   "metadata": {},
   "source": [
    "## N-Body GPU-accelerated Simulation in Python using Numba and CuPy\n",
    "*By Adrien GAGNE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1625a39",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa8c60f",
   "metadata": {},
   "source": [
    ">This project is a proof of concept, the goal is to render the formation of galaxy clusters with python. It is a way for me to learn and manipulate complex 3D simulations. This notebook is the result of multiple weeks of trials and errors that leaded to a functional simulation.\n",
    "\n",
    ">I chose the format of the notebook so that I could document my journey, but also for people to modify it and upgrade it. You are thus most welcome to send me your modifications on this project !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba653e70",
   "metadata": {},
   "source": [
    ">To compute a N-Body simulation I initially intended to use a simple \"every body interacts with each other\" method, but the time complexity of such algorithm is $O(N^2)$, which is not ideal. I then setteled on a classic Perodic Barnes Hut method $O(Nlog(N))$ with a stack-based traversal on the GPU, that will grant me the ability to render **1 million** bodies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f5566",
   "metadata": {},
   "source": [
    ">To meet the goal of a large-scale structure formation simulation, the intial cosmological conditions will use the Zel'dovich approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3c66f",
   "metadata": {},
   "source": [
    "#### Project Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66206c46",
   "metadata": {},
   "source": [
    "**Phase 1: Configuration & Cosmological Initial Conditions**\n",
    "- **1.1 Global Configuration**: Definition of physical constants ($G$, $H_0$), simulation parameters (N, box size, $\\theta$ opening angle), and CUDA block configurations.\n",
    "\n",
    "- **1.2 Zel'dovich Approximation (Initial Conditions)**: Implementation of a Gaussian Random Field generator using FFT (via CuPy) to displace particles from a uniform grid. This creates the initial density perturbations required for structure formation.\n",
    "\n",
    "**Phase 2: GPU Linear Octree Construction**\n",
    "- **2.1 Morton Encoding (Z-Order Curve)**: Kernel to compute Morton codes for all particles to map 3D positions to 1D indices.\n",
    "\n",
    "- **2.2 Radix Sort**: Sorting particles on the GPU based on Morton codes to ensure spatial locality.\n",
    "\n",
    "- **2.3 Tree Building (Linear Octree)**: A bottom-up approach to construct the tree hierarchy (leaf nodes $\\to$ internal nodes) directly in GPU memory, avoiding pointer-chasing structures.\n",
    "\n",
    "- **2.4 Multipole Moments**: Kernel to compute total mass and Center of Mass (COM) for each node in the tree (upward pass).\n",
    "\n",
    "**Phase 3: Physics Engine (The Kernel)**\n",
    "- **3.1 Stack-Based Tree Traversal**: The core logic. A CUDA kernel using local thread memory (simulated stack) to traverse the Octree without recursion.\n",
    "\n",
    "- **3.2 Force Calculation**: Computing gravitational acceleration with the Barnes-Hut acceptance criterion (MAC).\n",
    "\n",
    "- **3.3 Hubble Drag & Integration**: Applying the expanding universe drag term and updating particle kinematics using a Symplectic integrator.\n",
    "\n",
    "**Phase 4: In-Situ GPU Visualization**\n",
    "- **4.1 Density Projection Kernel**: A \"Splatting\" kernel that projects 3D particles onto a 2D accumulation buffer directly in GPU memory.\n",
    "\n",
    "- **4.2 Log-Scale Transfer Function**: Converting density values to RGB colors (mimicking the video's heat-map aesthetic) without CPU transfer.\n",
    "\n",
    "- **4.3 Output Pipeline**: Displaying the GPU buffer in the Jupyter environment.\n",
    "\n",
    "**Phase 5: Orchestration & Validation**\n",
    "- **5.1 Verification Cell**: Line-by-line testing logic.\n",
    "\n",
    "- **5.2 Simulation Loop**: The main driver loop handling time-stepping and frame rendering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3eebf",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258678af",
   "metadata": {},
   "source": [
    ">This project was written using a Geforce RTX 5070, it may not work (Performance wise) the same way on other devices. This project uses the following libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac29d41",
   "metadata": {},
   "source": [
    "- Numba\n",
    "- CuPy\n",
    "- Numba\n",
    "- Vispy\n",
    "- TQDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2fff4",
   "metadata": {},
   "source": [
    "### Phase 1: Configuration & Cosmological Initial Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152606d6",
   "metadata": {},
   "source": [
    "#### 1.1 Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa087b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cupy.fft import fftn, ifftn\n",
    "import numba\n",
    "from numba import cuda, uint64\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8303ef42",
   "metadata": {},
   "source": [
    ">For physics calculations units are arbitrary (called code units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1760f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SIMULATION PARAMETERS ---\n",
    "N_GRID = 100                  # Grid size per dimension\n",
    "N_PARTICLES = N_GRID**3      # Total particles (~262k for 64^3, 1M for 100^3)\n",
    "BOX_SIZE = 100.0             # Length of the periodic box side\n",
    "SOFTENING = 0.1              # Softening length to prevent singularities at r=0\n",
    "G = 1.0                      # Gravitational constant (code units)\n",
    "H0 = 50.0                     # Hubble parameter (expansion rate)\n",
    "DT = 0.005                    # Time step\n",
    "N_STEPS = 414                   # Total simulation steps\n",
    "A_START = 0.01               # Starting scale factor\n",
    "A_END = 1.0                 # Ending scale factor\n",
    "OMEGA_M = 1.0              # Matter density parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BARNES-HUT PARAMETERS ---\n",
    "THETA = 0.5                  # Opening angle for MAC (0.5 is standard trade-off)\n",
    "MAX_DEPTH = 18               # Max tree depth (octree)\n",
    "WARP_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZATION PARAMETERS ---\n",
    "RES = 1024                   # Render resolution (RES x RES)\n",
    "CMAP_GAMMA = 0.5             # Gamma correction for log-scale brightness\n",
    "OUTPUT_DIR = \"render_output\"\n",
    "VIDEO_NAME = \"nbody_simulation.mp4\"\n",
    "\n",
    "FOV = 60.0\n",
    "CAM_DIST_MULT = 1.8\n",
    "ROTATION_SPEED = 0.005 #Radians per frame\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CUDA CONFIGURATION ---\n",
    "TPB = 256                    # Threads Per Block\n",
    "BPG = (N_PARTICLES + TPB - 1) // TPB # Blocks Per Grid\n",
    "BATCH_SIZE = 16384\n",
    "BATCH_BPG = (BATCH_SIZE + TPB - 1) // TPB\n",
    "MAX_H_RATE = 1000.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TREE CONSTRUCTION ---\n",
    "num_nodes = 2 * N_PARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PHYSICS COMPUTATIONS ---\n",
    "drag_factor = 1.0 / (1.0 + H0 * DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde86165",
   "metadata": {},
   "source": [
    "#### 1.2 : Zel'Dovich Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6ae601",
   "metadata": {},
   "source": [
    ">Intial testing showed that a random repartitions of bodies in space will ultimately result in a global collapse in the center of the box or an equilibrium of all the bodies. No cluster appeared (renders without initial conditions)\n",
    "\n",
    "![Test Render](resources/1_1_test_animation.webp \"Example 1\")\n",
    "\n",
    "![Test Render 2](resources/1_2_test_render.webp \"Example 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a9f13",
   "metadata": {},
   "source": [
    ">It makes for a nice \"supernova\" style simulation, but that wasn't planned at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd983b",
   "metadata": {},
   "source": [
    ">The [Zeldovich approximation](https://en.wikipedia.org/wiki/Zeldovich_approximation) is used here to introduce a nonlinear evolution for the structure. The mathematical aspect of this is to use the following mass density:\n",
    ">$$\\rho(\\mathbf{x}, t) = \\frac{\\rho_0}{\\det \\left( \\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{q}} \\right)} = \\frac{\\rho_0}{\\det \\left( \\mathbf{I} + \\sigma(t) \\frac{\\partial \\mathbf{u}}{\\partial \\mathbf{q}} \\right)}$$\n",
    ">where:\n",
    ">- $\\rho_0$ is the mean background density,\n",
    ">- $x(t)$ is the comoving position (position that does not take into account space expanse) of a particle,\n",
    ">- $\\sigma(t)$ is the linear growth factor of density perturbations,\n",
    ">- $u$ is the initial displacement vector determined by the initial density field\n",
    ">- $q$ is the initial lagrangian position of the particle\n",
    "\n",
    ">Implementing this is done by generating a Gaussian random field inside our box and applying a power spectrum function $P(k) = 1/k^3$ and then compute the displacement in the Fourier space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_zeldovich_ics(n_grid, box_size, seed=42, spectral_index=2.0, amplitude=1.0):\n",
    "    \"\"\"\n",
    "    Generates Initial Conditions using the Zel'dovich approximation.\n",
    "    Method:\n",
    "    1- Generate a uniform 3D grid of particles (Lagrangian coordinates q).\n",
    "    2- Generate a Gaussian Random Field in Fourier space.\n",
    "    3- Apply a power spectrum P(k) ~ k^-n.\n",
    "    4- Compute displacement field via FFT.\n",
    "    5- Displace particles and assign initial velocities (Hubble flow + peculiar velocity).\n",
    "    \"\"\"\n",
    "    cp.random.seed(seed)\n",
    "\n",
    "    lins = cp.linspace(0, box_size, n_grid, endpoint=False) # Lagrangian grid\n",
    "\n",
    "    qx, qy, qz = cp.meshgrid(lins, lins, lins, indexing='ij') # coordinates of q (see above)\n",
    "    \n",
    "    # Fourier Space Setup\n",
    "    k = cp.fft.fftfreq(n_grid, d=box_size/n_grid) * 2 * cp.pi\n",
    "    kx, ky, kz = cp.meshgrid(k, k, k, indexing='ij')\n",
    "    k_sq = kx**2 + ky**2 + kz**2 # coordinates in fourier space (squared)\n",
    "    k_sq[0,0,0] = 1e-10 # Avoid division by zero at DC component\n",
    "\n",
    "    # The random Gaussian field in Fourier space\n",
    "    random_field = cp.random.normal(0, 1, (n_grid, n_grid, n_grid)) + \\\n",
    "                   1j * cp.random.normal(0, 1, (n_grid, n_grid, n_grid))\n",
    "    \n",
    "\n",
    "    # aplly power spectrum\n",
    "    power_spectrum = 1.0 / (k_sq ** (spectral_index / 2.0)) # P(k) ~ k^-2\n",
    "    power_spectrum[0,0,0] = 0\n",
    "    delta_k = random_field * cp.sqrt(power_spectrum)\n",
    "\n",
    "    #Compute displacement field\n",
    "    def get_displacement(k_component_grid):\n",
    "        term = 1j * k_component_grid / k_sq\n",
    "        term[0,0,0] = 0\n",
    "        disp_k = term * delta_k\n",
    "        return cp.fft.ifftn(disp_k).real * n_grid**3 \n",
    "    \n",
    "    dx = get_displacement(kx).flatten()\n",
    "    dy = get_displacement(ky).flatten()\n",
    "    dz = get_displacement(kz).flatten()\n",
    "\n",
    "    dx *= amplitude\n",
    "    dy *= amplitude\n",
    "    dz *= amplitude\n",
    "\n",
    "    \n",
    "    # x = q + D * dx with perodic wrap\n",
    "    pos_x = cp.mod(qx.flatten() + dx, box_size).astype(cp.float32)\n",
    "    pos_y = cp.mod(qy.flatten() + dy, box_size).astype(cp.float32)\n",
    "    pos_z = cp.mod(qz.flatten() + dz, box_size).astype(cp.float32)\n",
    "\n",
    "    H_start = H0 * (A_START ** (-1.5))\n",
    "    vel_factor = H_start * A_START * 0.8 #0.8 is arbitrary growth rate\n",
    "\n",
    "    #0.5 is arbitrary growth rate\n",
    "    vel_x = (dx * vel_factor * 0.5).astype(cp.float32)\n",
    "    vel_y = (dy * vel_factor * 0.5).astype(cp.float32)\n",
    "    vel_z = (dz * vel_factor * 0.5).astype(cp.float32)\n",
    "\n",
    "    mass = cp.ones(n_grid**3, dtype=cp.float32) # Uniform mass\n",
    "    \n",
    "    return (pos_x, pos_y, pos_z), (vel_x, vel_y, vel_z), mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35416e0c",
   "metadata": {},
   "source": [
    "### Phase 2 : Linear Octree Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6609f1",
   "metadata": {},
   "source": [
    ">The Barnes-Hut algorithm makes approximations, It considers that if $N_1$ bodies are close enough together they can be computed as a single mass body $m = \\sum_{i}^{N_1}(m_i)$.\\\n",
    ">To represent the 3-dimensional space, it uses an **Octree** (tree with strictly 8 branchs per node), the resolution per octant is determined by the amount of bodies in the octant. The search complexity for such tree is $O(LogN)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc9d78",
   "metadata": {},
   "source": [
    "#### 2.1 : Morton Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba683d",
   "metadata": {},
   "source": [
    ">The only issue here: GPU's don't like trees, or multiple dimension objects in general, what they really like is arrays (vectors). This is why everything (coordinates, octree, etc...) has to be \"flattened\" into arrays.\\\n",
    ">For the coordinates of the positions, velocities and accelerations, I found the Z-curve encoding to be good enough performance wise. Also called the **Morton encoding** it consist in interleaving coordinates together to obtain a single number.\n",
    "\n",
    ">Let's take the binary representation of the coordinates of the position of a body inside our space:\n",
    ">- $X = x_1x_2x_3$\n",
    ">- $Y = y_1y_2y_3$\n",
    ">- $Z = z_1z_2z_3$\n",
    "\n",
    ">The Morton encoding interleaves those bits together in the following way:\n",
    ">- $CODE = z_3y_3x_3z_2y_2x_2z_1y_1x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb30bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def expand_bits(v):\n",
    "    \"\"\"\n",
    "    Expands a 21-bit integer into 64 bits by inserting 2 zeros after each bit.\n",
    "    \"\"\"\n",
    "    v &= 0x1fffff # avoid overflow\n",
    "    v = (v | (v << 32)) & 0x1f00000000ffff\n",
    "    v = (v | (v << 16)) & 0x1f0000ff0000ff\n",
    "    v = (v | (v << 8))  & 0x100f00f00f00f00f\n",
    "    v = (v | (v << 4))  & 0x10c30c30c30c30c3\n",
    "    v = (v | (v << 2))  & 0x1249249249249249\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156778d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def get_morton_code(x, y, z, min_grid, grid_scale):\n",
    "    \"\"\"\n",
    "    Computes the 3D Morton code for a body given its position.\n",
    "    \"\"\"\n",
    "\n",
    "    ix = uint64((x - min_grid) * grid_scale)\n",
    "    iy = uint64((y - min_grid) * grid_scale)\n",
    "    iz = uint64((z - min_grid) * grid_scale)\n",
    "\n",
    "    return expand_bits(ix) | (expand_bits(iy) << 1) | (expand_bits(iz) << 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b975978",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def compute_morton_codes(pos_x, pos_y, pos_z, codes, n_bodies, grid_scale, indices):\n",
    "    \"\"\"\n",
    "    CUDA kernel to compute Morton codes for all particles.\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < n_bodies:\n",
    "        codes[idx] = get_morton_code(pos_x[idx], pos_y[idx], pos_z[idx], 0.0, grid_scale)\n",
    "        indices[idx] = idx # keep track of original indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c78c7",
   "metadata": {},
   "source": [
    "#### 2.2 : Radix Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f3797e",
   "metadata": {},
   "source": [
    ">The final array `codes` is big, an important step is to optimize the search inside of it by sorting it. Since the programm will mostly seek for neighbors when processing a body, It needs to be sorted relative to \"body proximity\".\n",
    ">To explain it better, sorting the morton codes will improve memory locality (Coalescing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07534dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bodies(pos, vel, mass):\n",
    "    \"\"\"\n",
    "    Radix sort all arrays based on their Morton codes.\n",
    "    \"\"\"\n",
    "    n = pos[0].shape[0]\n",
    "    min_coord = 0.0\n",
    "    grid_scale = ((2**21 - 2)/ BOX_SIZE) #Boundary issue solved by -2\n",
    "\n",
    "    codes = cp.zeros(n, dtype=cp.uint64)\n",
    "    indices = cp.zeros(n, dtype=cp.uint32)\n",
    "\n",
    "    compute_morton_codes[BPG, TPB](pos[0], pos[1], pos[2], codes, n, grid_scale, indices)\n",
    "\n",
    "    sort_idx = cp.argsort(codes) #Radix sort on GPU\n",
    "\n",
    "    pos_sorted = (pos[0][sort_idx], pos[1][sort_idx], pos[2][sort_idx])\n",
    "    vel_sorted = (vel[0][sort_idx], vel[1][sort_idx], vel[2][sort_idx])\n",
    "    mass_sorted = mass[sort_idx]\n",
    "    codes_sorted = codes[sort_idx]\n",
    "\n",
    "    return pos_sorted, vel_sorted, mass_sorted, codes_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b0b69",
   "metadata": {},
   "source": [
    "#### 2.3 : Tree Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d63230",
   "metadata": {},
   "source": [
    ">Now that was the easy part. The tree construction is going to be a bit more complex.\\\n",
    ">Fortunately, Nvidia researcher [**Tero Karras**](https://research.nvidia.com/person/tero-karras) published a really useful paper on [tree construction optimized for parallelism](https://research.nvidia.com/sites/default/files/pubs/2012-06_Maximizing-Parallelism-in/karras2012hpg_paper.pdf). The concept is rather simple:\n",
    "\n",
    "> - **The Linear Part**: Since GPU's work best with an 1D array and the tree is an *Octree*, then to get from node $i$ to it's fist child node, the math is the following $i_{child} = 8*i + 1$\n",
    ">- **The Parallelism Part**: Since the list of coordinates is already sorted (with *Morton Encoding*) the tree structure can be figured out just by looking at the bits of the Morton code of neighboring points.\\\n",
    ">If two adjacent points in the list share the first 3 bits of their code, they belong in the same \"large\" box. If they share the first 6 bits, they belong in the same \"medium\" sub-box.\\\n",
    "The point where the bits differ is exactly where the tree splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d7f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def delta_fn(codes, i, j, n):\n",
    "    \"\"\"\n",
    "    Computes the length of the longest common prefix between codes[i] and codes[j].\n",
    "    Handles boundary conditions.\n",
    "    \"\"\"\n",
    "    if j < 0 or j >= n:\n",
    "        return -1\n",
    "    \n",
    "    code_i = codes[i]\n",
    "    code_j = codes[j]\n",
    "\n",
    "    if code_i == code_j :\n",
    "        code_i, code_j = i, j # if duplicate codes\n",
    "        return 64 + (32 - cuda.clz(i ^ j)) #32 for int32 index collision\n",
    "    \n",
    "    return cuda.libdevice.clzll(numba.int64(code_i ^ code_j)) # CLZ shows shared prefix and XOR differing bits (czll because int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfc735",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def build_radix_tree_kernel(codes, children, parents):\n",
    "    \"\"\"\n",
    "    Constructs the internal nodes of the binary radix tree.\n",
    "    Each thread i (0 to N-2) constructs internal node (i + N).\n",
    "    \"\"\"\n",
    "\n",
    "    i = cuda.grid(1)\n",
    "    n = codes.shape[0]\n",
    "\n",
    "    if i >= n-1:\n",
    "        return\n",
    "    \n",
    "    idx = i + n #internal node index\n",
    "\n",
    "    d_prev = delta_fn(codes, i, i-1, n)\n",
    "    d_next = delta_fn(codes, i, i+1, n)\n",
    "\n",
    "    direction = 1\n",
    "    min_delta = d_prev\n",
    "    if d_next > d_prev:\n",
    "        direction = 1\n",
    "        min_delta = d_prev # Lower bound for split\n",
    "    else:\n",
    "        direction = -1\n",
    "        min_delta = d_next\n",
    "        \n",
    "    \n",
    "    l_max = 2\n",
    "    while delta_fn(codes, i, i + l_max * direction, n) > min_delta: # Determine upper bound of the range (l_max)\n",
    "        l_max *= 2 \n",
    "        \n",
    "    \n",
    "    l = 0\n",
    "    t = l_max // 2\n",
    "    while t >= 1:\n",
    "        if delta_fn(codes, i, i + (l + t) * direction, n) > min_delta: #Find the other end using binary search\n",
    "            l += t\n",
    "        t //= 2\n",
    "        \n",
    "    j = i + l * direction\n",
    "    \n",
    "    \n",
    "    delta_node = delta_fn(codes, i, j, n) \n",
    "    s = 0\n",
    "    t = l\n",
    "    while t > 0: # Find the split position (gamma)\n",
    "        \n",
    "        step = (t + 1) // 2 \n",
    "\n",
    "        check_idx = i + (s + step) * direction\n",
    "        if delta_fn(codes, i, check_idx, n) > delta_node: # Standard binary search to find split\n",
    "            s += step\n",
    "        t -= step\n",
    "        \n",
    "    gamma = i + s * direction\n",
    "    if direction == -1:\n",
    "        gamma -= 1 # Adjustment for reverse search\n",
    "\n",
    "    # Left child\n",
    "    left = gamma\n",
    "    right = gamma + 1\n",
    "    \n",
    "    range_left = min(i, j)\n",
    "    range_right = max(i, j)\n",
    "    \n",
    "\n",
    "    if range_left == gamma: #assign Left\n",
    "        children[idx, 0] = gamma #leaf\n",
    "    else:\n",
    "        children[idx, 0] = gamma + n #internal Node\n",
    "        \n",
    "\n",
    "    if range_right == gamma + 1: #assign Right\n",
    "        children[idx, 1] = gamma + 1 # Leaf\n",
    "    else:\n",
    "        children[idx, 1] = gamma + 1 + n # Internal Node\n",
    "\n",
    "    \n",
    "    parents[children[idx, 0]] = idx # Set Parents (needed for upward pass)\n",
    "    parents[children[idx, 1]] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba7a5c",
   "metadata": {},
   "source": [
    "#### 2.4 : Multipole Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027681ce",
   "metadata": {},
   "source": [
    ">Now, every \"Bodies\" have coordinates, initial velocities and a way to efficiently map them in space. But to compute the interactions in the Barnes-Hut method, every nodes need to have a mass value.\\\n",
    ">For every leafs the mass is already known and the center of mass (CoM) is their positions. The sum of those mass makes for the mass of the nodes and the CoM can be computed the same way.\\\n",
    ">To make those calculations easier to implement, and because the tree is easily traversed both way, the mass can be propagated from the leaf to the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def compute_multipoles_kernel(pos, mass, children, parents, node_mass, node_com, \n",
    "                              node_min, node_max, counters):\n",
    "    \"\"\"\n",
    "    Computes Mass, Center of Mass, and Bounding Box (AABB) for each node.\n",
    "    \"\"\"\n",
    "    idx = cuda.grid(1)\n",
    "    n_leaf = pos[0].shape[0]\n",
    "\n",
    "    pos_x, pos_y, pos_z = pos\n",
    "\n",
    "    if idx >= n_leaf:\n",
    "        return\n",
    "\n",
    "    #Initialize Leaf Nodes\n",
    "    m = mass[idx]\n",
    "    px = pos_x[idx]\n",
    "    py = pos_y[idx]\n",
    "    pz = pos_z[idx]\n",
    "\n",
    "    node_mass[idx] = m\n",
    "    node_com[idx, 0] = px\n",
    "    node_com[idx, 1] = py\n",
    "    node_com[idx, 2] = pz\n",
    "    \n",
    "    # Initialize AABB (Leaf min = max = pos)\n",
    "    node_min[idx, 0] = px\n",
    "    node_min[idx, 1] = py\n",
    "    node_min[idx, 2] = pz\n",
    "    node_max[idx, 0] = px\n",
    "    node_max[idx, 1] = py\n",
    "    node_max[idx, 2] = pz\n",
    "    \n",
    "    curr = idx\n",
    "\n",
    "    while True:\n",
    "        parent = parents[curr]\n",
    "        if parent == -1:\n",
    "            break \n",
    "        \n",
    "        cuda.threadfence()\n",
    "        old_val = cuda.atomic.add(counters, parent, 1)\n",
    "\n",
    "        if old_val == 0: \n",
    "            break # Wait for sibling\n",
    "\n",
    "        elif old_val == 1: # Second child creates the parent\n",
    "            left = children[parent, 0]\n",
    "            right = children[parent, 1]\n",
    "            \n",
    "            #mass and COM \n",
    "            m_l = node_mass[left]\n",
    "            m_r = node_mass[right]\n",
    "            sum_m = m_l + m_r\n",
    "            \n",
    "            if sum_m > 0:\n",
    "                inv_m = 1.0 / sum_m\n",
    "                cx = (node_com[left, 0] * m_l + node_com[right, 0] * m_r) * inv_m\n",
    "                cy = (node_com[left, 1] * m_l + node_com[right, 1] * m_r) * inv_m\n",
    "                cz = (node_com[left, 2] * m_l + node_com[right, 2] * m_r) * inv_m\n",
    "            else:\n",
    "                cx, cy, cz = 0.0, 0.0, 0.0\n",
    "\n",
    "            node_mass[parent] = sum_m\n",
    "            node_com[parent, 0] = cx\n",
    "            node_com[parent, 1] = cy\n",
    "            node_com[parent, 2] = cz\n",
    "            \n",
    "            # AABB merge\n",
    "            \n",
    "            # Min X\n",
    "            lx, rx = node_min[left, 0], node_min[right, 0]\n",
    "            node_min[parent, 0] = lx if lx < rx else rx\n",
    "            # Min Y\n",
    "            ly, ry = node_min[left, 1], node_min[right, 1]\n",
    "            node_min[parent, 1] = ly if ly < ry else ry\n",
    "            # Min Z\n",
    "            lz, rz = node_min[left, 2], node_min[right, 2]\n",
    "            node_min[parent, 2] = lz if lz < rz else rz\n",
    "            \n",
    "            # Max X\n",
    "            lx, rx = node_max[left, 0], node_max[right, 0]\n",
    "            node_max[parent, 0] = lx if lx > rx else rx\n",
    "            # Max Y\n",
    "            ly, ry = node_max[left, 1], node_max[right, 1]\n",
    "            node_max[parent, 1] = ly if ly > ry else ry\n",
    "            # Max Z\n",
    "            lz, rz = node_max[left, 2], node_max[right, 2]\n",
    "            node_max[parent, 2] = lz if lz > rz else rz\n",
    "\n",
    "            curr = parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155bd56",
   "metadata": {},
   "source": [
    ">Up to this point a \"Sanity check\" was important, in an ideal world the sum of the masses of the **leaves** had to be the sum of the masses of the **nodes**. But when comparing thoses values after multiple computations, a mass mismatch of ~$3\\%$ was observed.\\\n",
    ">Proably due to race conditions in memory, the `cuda.threadfence()` fixes it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1994e",
   "metadata": {},
   "source": [
    "### Phase 3: Physics Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08268af6",
   "metadata": {},
   "source": [
    ">This part is the heart of this project, the challenge is to calculate the gravitational force between every nodes and leaves. wheras the standard Barnes-Hut is recursive, this one cannot. The solution is to make it stack-less transversal:\n",
    ">- Simulate a stack using fixed-size array\n",
    ">- Push the root node onto the stack\n",
    ">- while the stack is not empty :\n",
    ">    - pop a node\n",
    ">    - check criteria ($disatnce/size > \\theta$)\n",
    ">    - if it is `True` compute force using node's mass\n",
    ">    - else, it's a leaf compute direct force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1642608",
   "metadata": {},
   "source": [
    ">Regarding periodic boundaries, for a cosmologically accurate simulation, the formula for the forces at stake near the edge of the box is the following:\n",
    ">$$\\mathbf{f}_{real} = - \\frac{G M}{r^3} \\mathbf{r} \\left[ \\text{erfc}(\\alpha r) + \\frac{2\\alpha r}{\\sqrt{\\pi}} \\exp(-\\alpha^2 r^2) \\right]$$\n",
    ">This is called the **Ewald Summation**, $\\alpha$ being the term controlling the split between the FFT and the Tree.\n",
    "\n",
    ">However, as this project is a visual proof of concept, it will use the **Nearest Image approximation** for the box edges. When calculating the distance between particle $i$ and node $j$, we choose the periodic image of $j$ closest to $i$.\n",
    ">- `dx = x_j - x_i`\n",
    ">- `dx = dx - box_size * round(dx / box_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def find_root_kernel(parents, root_idx):\n",
    "    i = cuda.grid(1)\n",
    "    if i < parents.shape[0]:\n",
    "        if parents[i] == -1:\n",
    "            root_idx[0] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d94bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(fastmath=True)\n",
    "def compute_forces_kernel(pos, mass, children, node_mass, node_com, \n",
    "                          node_min, node_max, force,\n",
    "                          theta, G, softening, box_size, root_idx, i_offset):\n",
    "    tid = cuda.grid(1)\n",
    "\n",
    "    i = tid + i_offset\n",
    "\n",
    "    if i >= pos[0].shape[0]:\n",
    "        return\n",
    "\n",
    "    p_pos_x = pos[0][i]\n",
    "    p_pos_y = pos[1][i]\n",
    "    p_pos_z = pos[2][i]\n",
    "\n",
    "    acc_x = 0.0\n",
    "    acc_y = 0.0\n",
    "    acc_z = 0.0\n",
    "\n",
    "    # Stack initialization\n",
    "    stack = cuda.local.array(96 , dtype=numba.int32) \n",
    "    stack_top = 0\n",
    "    stack[stack_top] = root_idx[0]\n",
    "    stack_top += 1\n",
    "    \n",
    "    theta_sq = theta * theta\n",
    "\n",
    "    while stack_top > 0:\n",
    "        stack_top -= 1\n",
    "        node_idx = stack[stack_top]\n",
    "        \n",
    "        # Load Mass\n",
    "        n_mass = node_mass[node_idx]\n",
    "        \n",
    "        #Skip empty nodes or extremely light nodes\n",
    "        if n_mass <= 0:\n",
    "            continue\n",
    "            \n",
    "        # Distance Calculation (Nearest Image)\n",
    "        dx = node_com[node_idx, 0] - p_pos_x\n",
    "        dy = node_com[node_idx, 1] - p_pos_y\n",
    "        dz = node_com[node_idx, 2] - p_pos_z\n",
    "        \n",
    "        dx -= box_size * round(dx / box_size)\n",
    "        dy -= box_size * round(dy / box_size)\n",
    "        dz -= box_size * round(dz / box_size)\n",
    "        \n",
    "        dist_sq = dx*dx + dy*dy + dz*dz + 1e-10\n",
    "        \n",
    "        is_leaf = (children[node_idx, 0] == -1)\n",
    "        apply_force = is_leaf\n",
    "        \n",
    "        if not is_leaf:\n",
    "            # AABB Size Calculation\n",
    "            sx = node_max[node_idx, 0] - node_min[node_idx, 0]\n",
    "            sy = node_max[node_idx, 1] - node_min[node_idx, 1]\n",
    "            sz = node_max[node_idx, 2] - node_min[node_idx, 2]\n",
    "            \n",
    "            # Clamp size for periodic boundary spanning nodes\n",
    "            # If a node spans > 50% of the box, it wraps.\n",
    "            if sx > box_size * 0.5: sx = box_size\n",
    "            if sy > box_size * 0.5: sy = box_size\n",
    "            if sz > box_size * 0.5: sz = box_size\n",
    "            \n",
    "            size_sq = sx*sx + sy*sy + sz*sz # Diagonal squared usually safer\n",
    "            \n",
    "            # MAC Criterion\n",
    "            if size_sq < (theta_sq * dist_sq):\n",
    "                apply_force = True\n",
    "        \n",
    "        # 2. Avoid Self-Interaction\n",
    "        if node_idx == i:\n",
    "            apply_force = False\n",
    "\n",
    "        if apply_force:\n",
    "            dist_soft = dist_sq + softening*softening\n",
    "            inv_dist = 1.0 / math.sqrt(dist_soft)\n",
    "            inv_dist_cube = inv_dist * inv_dist * inv_dist\n",
    "            f = G * n_mass * inv_dist_cube\n",
    "            \n",
    "            acc_x += f * dx\n",
    "            acc_y += f * dy\n",
    "            acc_z += f * dz\n",
    "            \n",
    "        elif not is_leaf: \n",
    "            # Stack Safety: Only push if there is room\n",
    "            if stack_top + 2 < 96:\n",
    "                stack[stack_top] = children[node_idx, 0]\n",
    "                stack_top += 1\n",
    "                stack[stack_top] = children[node_idx, 1]\n",
    "                stack_top += 1\n",
    "\n",
    "    force[i, 0] = acc_x\n",
    "    force[i, 1] = acc_y\n",
    "    force[i, 2] = acc_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def integrate_kernel(pos, vel, force, dt, box_size, drag_factor):\n",
    "    \"\"\"\n",
    "    Updates positions and velocities.\n",
    "    Includes 'drag_factor' to simulate Hubble expansion drag (a(t)).\n",
    "    v_{i+1} = v_i + a * dt\n",
    "    x_{i+1} = x_i + v_{i+1} * dt\n",
    "    \"\"\"\n",
    "    i = cuda.grid(1)\n",
    "    if i >= pos[0].shape[0]:\n",
    "        return\n",
    "\n",
    "    pos_x, pos_y, pos_z = pos\n",
    "    vel_x, vel_y, vel_z = vel\n",
    "\n",
    "    vx = vel_x[i] + force[i, 0] * dt\n",
    "    vy = vel_y[i] + force[i, 1] * dt\n",
    "    vz = vel_z[i] + force[i, 2] * dt\n",
    "\n",
    "    vx *= drag_factor\n",
    "    vy *= drag_factor\n",
    "    vz *= drag_factor\n",
    "    \n",
    "    max_v = box_size * 0.1 / dt\n",
    "    v_sq = vx*vx + vy*vy + vz*vz\n",
    "    if v_sq > max_v*max_v:\n",
    "        scale = max_v / math.sqrt(v_sq)\n",
    "        vx *= scale\n",
    "        vy *= scale\n",
    "        vz *= scale\n",
    "\n",
    "    # Update Position\n",
    "    px = pos_x[i] + vx * dt\n",
    "    py = pos_y[i] + vy * dt\n",
    "    pz = pos_z[i] + vz * dt\n",
    "\n",
    "    # Periodic Wrap\n",
    "    px = px % box_size\n",
    "    py = py % box_size\n",
    "    pz = pz % box_size\n",
    "    \n",
    "    if px < 0: px += box_size\n",
    "    if py < 0: py += box_size\n",
    "    if pz < 0: pz += box_size\n",
    "\n",
    "    # Store\n",
    "    vel_x[i] = vx\n",
    "    vel_y[i] = vy\n",
    "    vel_z[i] = vz\n",
    "    pos_x[i] = px\n",
    "    pos_y[i] = py\n",
    "    pos_z[i] = pz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a36871",
   "metadata": {},
   "source": [
    "https://people.eecs.berkeley.edu/~kubitron/courses/cs262a-F21/projects/reports/project16_report_ver3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc3560",
   "metadata": {},
   "source": [
    "### Phase 4 : Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad8701",
   "metadata": {},
   "source": [
    ">The slow part of rendering is the data traveling back and forth from the GPU to the CPU. Fixing that is doing point splatting instead of rendering gaussian spheres.\\\n",
    ">For the resolution of $1024^2$, the $10^6$ bodies will create perfect aliased density map. Then applying a logarithmic transfer function will make the filaments appear while preventing big clusters to shine too bright."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968c926",
   "metadata": {},
   "source": [
    ">The following functions run on CPU as they only run once per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64593121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    return v if norm == 0 else v / norm\n",
    "\n",
    "def look_at(eye, target, up):\n",
    "    \"\"\"\n",
    "    Creates a View Matrix.\n",
    "    \"\"\"\n",
    "    z = normalize(eye - target)\n",
    "    x = normalize(np.cross(up, z))\n",
    "    y = normalize(np.cross(z, x))\n",
    "\n",
    "    view = np.identity(4, dtype=np.float32)\n",
    "    view[0, :3] = x\n",
    "    view[1, :3] = y\n",
    "    view[2, :3] = z\n",
    "    view[0, 3] = -np.dot(x, eye)\n",
    "    view[1, 3] = -np.dot(y, eye)\n",
    "    view[2, 3] = -np.dot(z, eye)\n",
    "    \n",
    "    return view\n",
    "\n",
    "def perspective(fov_deg, aspect, near, far):\n",
    "    \"\"\"\n",
    "    Creates a Perspective Projection Matrix.\n",
    "    \"\"\"\n",
    "    fov_rad = np.radians(fov_deg)\n",
    "    f = 1.0 / np.tan(fov_rad / 2.0)\n",
    "    \n",
    "    proj = np.zeros((4, 4), dtype=np.float32)\n",
    "    proj[0, 0] = f / aspect\n",
    "    proj[1, 1] = f\n",
    "    proj[2, 2] = (far + near) / (near - far)\n",
    "    proj[2, 3] = (2 * far * near) / (near - far)\n",
    "    proj[3, 2] = -1.0\n",
    "    \n",
    "    return proj\n",
    "\n",
    "def get_mvp_matrix(step, box_center, box_size):\n",
    "    \"\"\"\n",
    "    Calculates the full MVP matrix for the current time step.\n",
    "    Orbit logic: Circular path on XZ plane, looking at center.\n",
    "    \"\"\"\n",
    "    angle = step * ROTATION_SPEED\n",
    "    radius = box_size * CAM_DIST_MULT\n",
    "    \n",
    "    # Orbiting position\n",
    "    eye_x = box_center[0] + radius * np.cos(angle)\n",
    "    eye_y = box_center[1] + (box_size * 0.2) # Slight elevation\n",
    "    eye_z = box_center[2] + radius * np.sin(angle)\n",
    "    \n",
    "    eye = np.array([eye_x, eye_y, eye_z], dtype=np.float32)\n",
    "    target = np.array(box_center, dtype=np.float32)\n",
    "    up = np.array([0, 1, 0], dtype=np.float32)\n",
    "    \n",
    "    view = look_at(eye, target, up)\n",
    "    proj = perspective(FOV, 1.0, 0.1, radius * 3.0)\n",
    "    \n",
    "    # Model matrix is Identity (simulation coordinates are world coordinates)\n",
    "    mvp = np.dot(proj, view)\n",
    "    return mvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def render_3d_density_kernel(pos, grid, mvp, width, height):\n",
    "    \"\"\"\n",
    "    Projects 3D world coordinates to 2D screen coordinates using MVP matrix.\n",
    "    Performs perspective division and atomic accumulation.\n",
    "    \"\"\"\n",
    "    i = cuda.grid(1)\n",
    "    if i < pos[0].shape[0]:\n",
    "        # Load Particle Position (x, y, z, 1.0)\n",
    "        px = pos[0][i]\n",
    "        py = pos[1][i]\n",
    "        pz = pos[2][i]\n",
    "        pw = 1.0\n",
    "        \n",
    "        # Matrix Multiplication: v_clip = MVP * v_world\n",
    "        # Rows of MVP are hardcoded for performance (unroll loop)\n",
    "        c_x = mvp[0,0]*px + mvp[0,1]*py + mvp[0,2]*pz + mvp[0,3]*pw\n",
    "        c_y = mvp[1,0]*px + mvp[1,1]*py + mvp[1,2]*pz + mvp[1,3]*pw\n",
    "        c_z = mvp[2,0]*px + mvp[2,1]*py + mvp[2,2]*pz + mvp[2,3]*pw\n",
    "        c_w = mvp[3,0]*px + mvp[3,1]*py + mvp[3,2]*pz + mvp[3,3]*pw\n",
    "        \n",
    "        # Frustum Culling (simple w check)\n",
    "        if c_w <= 0.001:\n",
    "            return\n",
    "            \n",
    "        # Perspective Divide (Clip Space -> NDC)\n",
    "        inv_w = 1.0 / c_w\n",
    "        ndc_x = c_x * inv_w\n",
    "        ndc_y = c_y * inv_w\n",
    "        ndc_z = c_z * inv_w # Depth, not used for splatting but good to have\n",
    "        \n",
    "        # Viewport Transform (NDC -> Screen Coordinates)\n",
    "        # NDC is [-1, 1]. Map to [0, width]\n",
    "        screen_x = (ndc_x + 1.0) * 0.5 * width\n",
    "        screen_y = (1.0 - ndc_y) * 0.5 * height # Flip Y for image coords\n",
    "        \n",
    "        # Bounds Check\n",
    "        ix = int(screen_x)\n",
    "        iy = int(screen_y)\n",
    "        \n",
    "        if 0 <= ix < width and 0 <= iy < height:\n",
    "            # Splat density\n",
    "            # Depth weighting could be added here (1/c_w), but flat 1.0 looks good for \"glowing\" gas\n",
    "            cuda.atomic.add(grid, (iy, ix), 1.0)\n",
    "\n",
    "# Allocate Density Buffer\n",
    "density_grid_d = cp.zeros((RES, RES), dtype=cp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_frame(pos_d, step):\n",
    "    \"\"\"\n",
    "    Orchestrates the 3D frame generation.\n",
    "    1. Computes Host MVP matrix.\n",
    "    2. Sends MVP to Device.\n",
    "    3. Runs Kernel.\n",
    "    4. Colors and converts to Image.\n",
    "    \"\"\"\n",
    "    # 1. Clear Grid\n",
    "    density_grid_d.fill(0)\n",
    "    \n",
    "    # 2. Compute Matrix (Host)\n",
    "    box_center = (BOX_SIZE/2, BOX_SIZE/2, BOX_SIZE/2)\n",
    "    mvp_host = get_mvp_matrix(step, box_center, BOX_SIZE)\n",
    "    mvp_device = cp.asarray(mvp_host) # Transfer to GPU\n",
    "    \n",
    "    # 3. Render\n",
    "    render_3d_density_kernel[BPG, TPB](pos_d, density_grid_d, mvp_device, RES, RES)\n",
    "    \n",
    "    # 4. Coloring (Logarithmic Transfer Function)\n",
    "    img_d = cp.log1p(density_grid_d)\n",
    "    v_max = cp.max(img_d) + 1e-5\n",
    "    img_d /= v_max\n",
    "    \n",
    "    # \"Cosmic Web\" Palette\n",
    "    r = cp.clip(img_d * 1.5 - 0.5, 0, 1) \n",
    "    g = cp.clip(img_d * 0.8, 0, 1)\n",
    "    b = cp.clip(img_d * 0.8 + 0.2, 0, 1)\n",
    "    \n",
    "    mask = (img_d > 0.0)\n",
    "    r *= mask\n",
    "    g *= mask\n",
    "    b *= mask\n",
    "    \n",
    "    rgb_d = cp.stack((r, g, b), axis=-1)\n",
    "    \n",
    "    return Image.fromarray((rgb_d.get() * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_3d_frame_gpu(pos_d, step, video_buffer_d):\n",
    "    \"\"\"\n",
    "    Renders the frame and stores it directly into the GPU video buffer.\n",
    "    No CPU transfer happens here.\n",
    "    \"\"\"\n",
    "    density_grid_d.fill(0)\n",
    "    \n",
    "    # 2. Compute Matrix (Host side - very fast)\n",
    "    # We calculate camera position based on 'step'\n",
    "    box_center = (BOX_SIZE/2, BOX_SIZE/2, BOX_SIZE/2)\n",
    "    mvp_host = get_mvp_matrix(step, box_center, BOX_SIZE)\n",
    "    mvp_device = cp.asarray(mvp_host) \n",
    "    \n",
    "    # 3. Render Geometry\n",
    "    render_3d_density_kernel[BPG, TPB](pos_d, density_grid_d, mvp_device, RES, RES)\n",
    "    \n",
    "    # 4. Coloring (All on GPU)\n",
    "    img_d = cp.log1p(density_grid_d)\n",
    "    v_max = cp.max(img_d) + 1e-5\n",
    "    img_d /= v_max\n",
    "    \n",
    "    # \"Cosmic Web\" Palette\n",
    "    r = cp.clip(img_d * 1.5 - 0.5, 0, 1) \n",
    "    g = cp.clip(img_d * 0.8, 0, 1)\n",
    "    b = cp.clip(img_d * 0.8 + 0.2, 0, 1)\n",
    "    \n",
    "    mask = (img_d > 0.0)\n",
    "    r *= mask\n",
    "    g *= mask\n",
    "    b *= mask\n",
    "    \n",
    "    # Stack channels\n",
    "    rgb_d = cp.stack((r, g, b), axis=-1)\n",
    "    \n",
    "    # 5. Store in the Main Video Buffer (Cast to uint8 to save VRAM)\n",
    "    # video_buffer_d is shape (N_STEPS, RES, RES, 3)\n",
    "    video_buffer_d[step] = (rgb_d * 255).astype(cp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3378db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_video(image_folder, output_file, fps=30):\n",
    "    \"\"\"\n",
    "    Compiles a sequence of PNGs into an MP4 using FFmpeg.\n",
    "    \"\"\"\n",
    "    print(\"Compiling Video...\")\n",
    "    \n",
    "    # FFmpeg command:\n",
    "    # -y: Overwrite output\n",
    "    # -framerate: Input FPS\n",
    "    # -i: Input pattern\n",
    "    # -c:v libx264: H.264 Codec\n",
    "    # -pix_fmt yuv420p: Ensure compatibility with players\n",
    "    cmd = [\n",
    "        'ffmpeg',\n",
    "        '-y',\n",
    "        '-framerate', str(fps),\n",
    "        '-i', f'{image_folder}/frame_%04d.png',\n",
    "        '-c:v', 'libx264',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        output_file\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(f\"Video saved successfully: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error compiling video.\")\n",
    "        print(e.stderr.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295e1a4",
   "metadata": {},
   "source": [
    "### Phase 5 : Loop and Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eb733",
   "metadata": {},
   "source": [
    ">The cycle here is the following: execute the full Barnes-Hut cycle (Sort $\\to$ Build $\\to$ Mass $\\to$ Force $\\to$ Integrate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44b7bd",
   "metadata": {},
   "source": [
    ">All memory allocation is done at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MEMORY ALLOCATION ---\n",
    "children_d = cp.full((num_nodes, 2), -1, dtype=cp.int32)\n",
    "parents_d = cp.full(num_nodes, -1, dtype=cp.int32)\n",
    "node_mass_d = cp.zeros(num_nodes, dtype=cp.float32)\n",
    "node_com_d = cp.zeros((num_nodes, 3), dtype=cp.float32)\n",
    "counters_d = cp.zeros(num_nodes, dtype=cp.int32)\n",
    "force_d = cp.zeros((N_PARTICLES, 3), dtype=cp.float32)\n",
    "root_idx_d = cp.zeros(1, dtype=cp.int32)\n",
    "\n",
    "node_min_d = cp.zeros((num_nodes, 3), dtype=cp.float32) #Bottleneck compute forces\n",
    "node_max_d = cp.zeros((num_nodes, 3), dtype=cp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76f9b0",
   "metadata": {},
   "source": [
    ">Now let's compute initial disturbation with Zel'dovich algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5847e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INITIALIZATION ---\n",
    "print(f\"Initializing Simulation: {N_PARTICLES} particles\")\n",
    "pos_d, vel_d, mass_d = generate_zeldovich_ics(N_GRID, BOX_SIZE, spectral_index=2.2, amplitude=25.0)\n",
    "a = A_START\n",
    "delta_a = (A_END - A_START) / N_STEPS\n",
    "\n",
    "print(f\"Allocating VRAM for {N_STEPS} frames... ({N_STEPS * RES**2 * 3 / 1e9:.2f} GB)\")\n",
    "video_buffer_d = cp.zeros((N_STEPS, RES, RES, 3), dtype=cp.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b306e4",
   "metadata": {},
   "source": [
    ">And finally, maybe the center of the programm, looping everything and storing frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Starting Render -> {OUTPUT_DIR}/\")\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "cuda.synchronize()\n",
    "\n",
    "# Create the progress bar object\n",
    "with tqdm(range(N_STEPS), desc=\"Simulating\") as pbar:\n",
    "    \n",
    "    for step in pbar:\n",
    "        \n",
    "        H_current = H0 * (a ** -1.5)\n",
    "        if H_current > MAX_H_RATE: H_current = MAX_H_RATE\n",
    "        drag_factor = 1.0 / (1.0 + 2.0 * H_current * DT) \n",
    "\n",
    "        pos_d, vel_d, mass_d, codes_d = sort_bodies(pos_d, vel_d, mass_d)\n",
    "        \n",
    "        children_d.fill(-1)\n",
    "        parents_d.fill(-1)\n",
    "        build_radix_tree_kernel[BPG, TPB](codes_d, children_d, parents_d)\n",
    "\n",
    "\n",
    "        counters_d.fill(0) #reset counters\n",
    "        node_mass_d.fill(0)\n",
    "        node_com_d.fill(0)\n",
    "        node_min_d.fill(0) \n",
    "        node_max_d.fill(0)\n",
    "\n",
    "        compute_multipoles_kernel[BPG, TPB](pos_d, mass_d, children_d, parents_d, \n",
    "                                            node_mass_d, node_com_d, \n",
    "                                            node_min_d, node_max_d, counters_d)\n",
    "        find_root_kernel[BPG, TPB](parents_d, root_idx_d)\n",
    "        \n",
    "        for i_offset in range(0, N_PARTICLES, BATCH_SIZE): #Batching logic to avoid TDR\n",
    "            current_batch = min(BATCH_SIZE, N_PARTICLES - i_offset)\n",
    "            blocks = (current_batch + TPB - 1) // TPB\n",
    "            compute_forces_kernel[blocks, TPB](pos_d, mass_d, children_d, \n",
    "                                               node_mass_d, node_com_d, \n",
    "                                               node_min_d, node_max_d, \n",
    "                                               force_d, THETA, G, SOFTENING, BOX_SIZE, \n",
    "                                               root_idx_d, i_offset)\n",
    "            \n",
    "        integrate_kernel[BPG, TPB](pos_d, vel_d, force_d, DT, BOX_SIZE, drag_factor)\n",
    "    \n",
    "        generate_3d_frame_gpu(pos_d, step, video_buffer_d)\n",
    "        a += delta_a\n",
    "\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d17c128",
   "metadata": {},
   "source": [
    ">Now that the simulation is done and that all frames are stored in the VRAM, everything can be sent back to CPU to be compiled into a nice video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame_to_disk(idx, frame_data, output_dir):\n",
    "    \"\"\"\n",
    "    Helper function for the thread pool\n",
    "    \"\"\"\n",
    "    img = Image.fromarray(frame_data)\n",
    "    img.save(f\"{output_dir}/frame_{idx:04d}.png\")\n",
    "\n",
    "print(\"Transferring video from GPU to CPU...\")\n",
    "video_buffer_host = video_buffer_d.get() # The big transfer (1.8GB)\n",
    "print(\"Transfer Complete. Saving frames to disk...\")\n",
    "\n",
    "# Parallel saving (Uses CPU cores efficiently)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for i in range(N_STEPS):\n",
    "        futures.append(executor.submit(save_frame_to_disk, i, video_buffer_host[i], OUTPUT_DIR))\n",
    "    \n",
    "    # Wait for all to finish\n",
    "    for _ in tqdm(concurrent.futures.as_completed(futures), total=N_STEPS, desc=\"Writing PNGs\"):\n",
    "        pass\n",
    "\n",
    "print(\"All frames saved.\")\n",
    "\n",
    "# Compile Video\n",
    "compile_video(OUTPUT_DIR, VIDEO_NAME, fps=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8eeb4",
   "metadata": {},
   "source": [
    ">Up to this point the pattern was the following Render $\\to$ Download $\\to$ Save $\\to$ Repeat which was not optimal. To tackle that performance issue, everything is now stored in device memory and all frames are sent back at the end of the simulation for compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a67aa3",
   "metadata": {},
   "source": [
    ">The following cell is for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78739976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_event = cp.cuda.Event()\n",
    "end_event = cp.cuda.Event()\n",
    "\n",
    "def profile_step():\n",
    "    #Sort\n",
    "    start_event.record()\n",
    "    pos_s, vel_s, mass_s, codes_s = sort_bodies(pos_d, vel_d, mass_d)\n",
    "    end_event.record()\n",
    "    end_event.synchronize()\n",
    "    t_sort = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "\n",
    "    #Build Tree\n",
    "    start_event.record()\n",
    "    build_radix_tree_kernel[BPG, TPB](codes_s, children_d, parents_d)\n",
    "    end_event.record()\n",
    "    end_event.synchronize()\n",
    "    t_build = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "\n",
    "    #Multipoles\n",
    "    start_event.record()\n",
    "    counters_d.fill(0)\n",
    "    node_mass_d.fill(0)\n",
    "    node_com_d.fill(0)\n",
    "    compute_multipoles_kernel[BPG, TPB](pos_s, mass_s, children_d, parents_d, \n",
    "                                        node_mass_d, node_com_d, \n",
    "                                        node_min_d, node_max_d, counters_d)\n",
    "    find_root_kernel[BPG, TPB](parents_d, root_idx_d)\n",
    "    end_event.record()\n",
    "    end_event.synchronize()\n",
    "    t_mass = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "\n",
    "    #Forces\n",
    "    start_event.record()\n",
    "    compute_forces_kernel[BPG, TPB](pos_s, mass_s, children_d, node_mass_d, node_com_d, \n",
    "                                    node_min_d, node_max_d, force_d, \n",
    "                                    THETA, G, SOFTENING, BOX_SIZE, root_idx_d, 0)\n",
    "    end_event.record()\n",
    "    end_event.synchronize()\n",
    "    t_force = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "\n",
    "    print(f\"Sort: {t_sort:.2f}ms\")\n",
    "    print(f\"Tree Build: {t_build:.2f}ms\")\n",
    "    print(f\"Mass Calc: {t_mass:.2f}ms\")\n",
    "    print(f\"Force Calc: {t_force:.2f}ms\")\n",
    "\n",
    "print(\"Profiling one step...\")\n",
    "profile_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a03a4e",
   "metadata": {},
   "source": [
    "![image.png](resources/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86234ff3",
   "metadata": {},
   "source": [
    ">The programm is running at ~7s/it which is good but not great. Some profiling gives us the culprit:\\\n",
    "`Profiling one step...`\\\n",
    "`Sort: 25.41ms`\\\n",
    "`Tree Build: 2.27ms`\\\n",
    "`Mass Calc: 15.90ms`\\\n",
    "`Force Calc: 6845.38ms`\n",
    "\n",
    ">The force calculation is taking more than 6s to compute! And this is likely due to the fact that the previous implementation was forcing the GPU to \"open\" any nodes closer than $10\\%$ of the box size. Making the complexity in dense areas drop to O($N^2$).\\\n",
    ">Fixing this requires to add [Axis-Aligned Bounding Box logic](https://en.wikipedia.org/wiki/Bounding_volume) to the multipole compute kernel.\\\n",
    ">Adding to that a batching logic to help with smooth computation (No spikes).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d5fd7",
   "metadata": {},
   "source": [
    ">Once implemented the profiling gives us ~2.8 s/it and the GPU is now running at ~98% without spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f94424a",
   "metadata": {},
   "source": [
    "### Phase 6: Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a03d0",
   "metadata": {},
   "source": [
    ">Some Renders:\\\n",
    ">The folowing ones were early results with basic random initial condition and/or basic euler integrations.\n",
    "\n",
    "| \"The messy magma\"  | \"Increased energy\" |\n",
    "| ------------- |:-------------:|\n",
    "| ![old_render4](resources/render_4.webp \"Old render 1\")      | ![old_render5](resources/render_5.webp \"Old render 1\")     |\n",
    "| \"The Wrong Zel'Dovich\"      | \"The chill guy\"     |\n",
    "| ![old_render6](resources/render_6.webp \"Old render 1\")      | ![old_render7](resources/render_7.webp \"Old render 1\")     |\n",
    "| \"The Pink supernova\"      | \"The Blue Supernova\"     |\n",
    "| ![old_render1](resources/1_1_test_animation.webp \"Old render 1\")      | ![old_render1](resources/1_2_test_render.webp \"Old render 1\")     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33809cd",
   "metadata": {},
   "source": [
    ">This one had a power function of $k^{-3}$ which puts almost all the energy into large-scale waves (low $k$) and very little into small-scale waves (high $k$).\n",
    ">The hubble drag and softening were too strong.\\\n",
    ">This said some galaxies can be seen!\n",
    "![old_render1](resources/render_3.webp \"Old render 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3e4e3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbody_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
